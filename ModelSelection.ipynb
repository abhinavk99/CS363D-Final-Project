{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets construct the different models that we will use.\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "# read data engineered csv\n",
    "# df = pd.read_csv('H-2B_Engineered_Data.csv')\n",
    "df = pd.read_csv('H-2B_Engineered_Data_Both.csv')\n",
    "# df = pd.read_csv('H-2B_Engineered_Data_Downsampling_Only.csv')\n",
    "labels = df.loc[:,'CASE_STATUS']\n",
    "features = pd.DataFrame(df.drop(labels = ['CASE_STATUS'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import neighbors as knn\n",
    "from sklearn import pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Build a preprocessor to scale numeric features and one hot encode categorical features\n",
    "numeric_features = ['NBR_WORKERS_REQUESTED', \n",
    "                    'BASIC_NUMBER_OF_HOURS', \n",
    "                    'BASIC_RATE_OF_PAY', \n",
    "                    'SUPERVISE_HOW_MANY', \n",
    "                    'NUM_OF_MONTHS_TRAINING',\n",
    "                    'EMP_EXP_NUM_MONTHS',\n",
    "                    'WORK_DAY_LENGTH']\n",
    "numeric_transformer = pipeline.Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())])\n",
    "\n",
    "categorical_features = ['SOC_CODE',\n",
    "                        'NAICS_CODE',\n",
    "                       'NATURE_OF_TEMPORARY_NEED',\n",
    "                       'EDUCATION_LEVEL',\n",
    "                       'CITY_MATCH',\n",
    "                       'STATE_MATCH']\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder(sparse = False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to figure out the best parameters for Decision Tree, K Nearest Neighbors, SVM, Random Forest Classifier, and MLP Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tree__criterion': 'entropy', 'tree__max_depth': 20, 'tree__max_features': 15, 'tree__min_samples_leaf': 5}\n",
      "0.8277323645171056\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {\n",
    "    'tree__max_depth': [5, 10, 15, 20],\n",
    "    'tree__min_samples_leaf': [5, 10, 15, 20], \n",
    "    'tree__max_features': [5, 10, 15],\n",
    "    'tree__criterion': ['gini', 'entropy']\n",
    "}\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('tree', tree.DecisionTreeClassifier())])\n",
    "tree_model = GridSearchCV(pipe, param_grid=tuned_parameters, scoring='accuracy', cv=5)\n",
    "tree_model.fit(features, labels)\n",
    "print(tree_model.best_params_)\n",
    "print(tree_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 1}\n",
      "0.8870723584620043\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {\n",
    "    'knn__n_neighbors': list(range(1, 25))\n",
    "}\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('knn', neighbors.KNeighborsClassifier())])\n",
    "knn_model = GridSearchCV(pipe, param_grid=tuned_parameters, scoring='accuracy', cv=5)\n",
    "knn_model.fit(features, labels)\n",
    "print(knn_model.best_params_)\n",
    "print(knn_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 2, 'svm__kernel': 'rbf'}\n",
      "0.7962458371177717\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {\n",
    "    'svm__C': [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2],\n",
    "    'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('svm', svm.SVC(gamma='auto'))])\n",
    "svm_model = GridSearchCV(pipe, param_grid=tuned_parameters, scoring='accuracy', cv=5)\n",
    "svm_model.fit(features, labels)\n",
    "print(svm_model.best_params_)\n",
    "print(svm_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'net__activation': 'relu', 'net__solver': 'adam'}\n",
      "0.8522555252800484\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "tuned_parameters = {\n",
    "    'net__activation': ['logistic', 'tanh', 'relu'],\n",
    "    'net__solver': ['sgd', 'adam']\n",
    "}\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('net', neural_network.MLPClassifier())])\n",
    "net_model = GridSearchCV(pipe, param_grid=tuned_parameters, scoring='accuracy', cv=5)\n",
    "net_model.fit(features, labels)\n",
    "print(net_model.best_params_)\n",
    "print(net_model.best_score_)\n",
    "\n",
    "warnings.simplefilter(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rfc__max_depth': 44, 'rfc__max_features': 'sqrt', 'rfc__min_samples_leaf': 8}\n",
      "0.8483197093551317\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "tuned_parameters = {\n",
    "    'rfc__max_depth': list(range(35, 56)),\n",
    "    'rfc__min_samples_leaf': list(range(8, 13, 2)),\n",
    "    'rfc__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('rfc', ensemble.RandomForestClassifier(n_estimators=10))])\n",
    "rfc_model = GridSearchCV(pipe, param_grid=tuned_parameters, scoring='accuracy', cv=5)\n",
    "rfc_model.fit(features, labels)\n",
    "print(rfc_model.best_params_)\n",
    "print(rfc_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make our classifiers based on the parameters that we have tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "#classifiers\n",
    "tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=20, max_features=15, min_samples_leaf=5)\n",
    "classifiers.append(('tree', tree))\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=10, max_depth=44, max_features='sqrt', min_samples_leaf=8)\n",
    "classifiers.append(('rfc', rfc))\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "classifiers.append(('knn', knn))\n",
    "\n",
    "nb = naive_bayes.GaussianNB()\n",
    "classifiers.append(('nb', nb))\n",
    "\n",
    "sv = svm.SVC(gamma='auto', C=2.0, kernel='rbf')\n",
    "classifiers.append(('svm', sv))\n",
    "\n",
    "net = neural_network.MLPClassifier(activation='relu', solver='adam')\n",
    "classifiers.append(('neural_network', net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
      "                       max_features=15, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[[1319  259]\n",
      " [ 302 1423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1578\n",
      "           1       0.85      0.82      0.84      1725\n",
      "\n",
      "    accuracy                           0.83      3303\n",
      "   macro avg       0.83      0.83      0.83      3303\n",
      "weighted avg       0.83      0.83      0.83      3303\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=44, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=8, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[1359  219]\n",
      " [ 321 1404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83      1578\n",
      "           1       0.87      0.81      0.84      1725\n",
      "\n",
      "    accuracy                           0.84      3303\n",
      "   macro avg       0.84      0.84      0.84      3303\n",
      "weighted avg       0.84      0.84      0.84      3303\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "                     weights='uniform')\n",
      "[[1457  121]\n",
      " [ 252 1473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89      1578\n",
      "           1       0.92      0.85      0.89      1725\n",
      "\n",
      "    accuracy                           0.89      3303\n",
      "   macro avg       0.89      0.89      0.89      3303\n",
      "weighted avg       0.89      0.89      0.89      3303\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[[ 599  979]\n",
      " [ 238 1487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.38      0.50      1578\n",
      "           1       0.60      0.86      0.71      1725\n",
      "\n",
      "    accuracy                           0.63      3303\n",
      "   macro avg       0.66      0.62      0.60      3303\n",
      "weighted avg       0.66      0.63      0.61      3303\n",
      "\n",
      "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[[1193  385]\n",
      " [ 288 1437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      1578\n",
      "           1       0.79      0.83      0.81      1725\n",
      "\n",
      "    accuracy                           0.80      3303\n",
      "   macro avg       0.80      0.79      0.80      3303\n",
      "weighted avg       0.80      0.80      0.80      3303\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "[[1293  285]\n",
      " [ 229 1496]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1578\n",
      "           1       0.84      0.87      0.85      1725\n",
      "\n",
      "    accuracy                           0.84      3303\n",
      "   macro avg       0.84      0.84      0.84      3303\n",
      "weighted avg       0.84      0.84      0.84      3303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# The results from the individual classifiers\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "for name, cl in classifiers:\n",
    "    pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', cl)])\n",
    "    pr = model_selection.cross_val_predict(pipe, features, labels, cv=5)\n",
    "    \n",
    "    print(cl)\n",
    "    print(metrics.confusion_matrix(labels, pr))\n",
    "    print(metrics.classification_report(labels, pr))\n",
    "    \n",
    "warnings.simplefilter(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('tree',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='entropy',\n",
      "                                                     max_depth=20,\n",
      "                                                     max_features=15,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=5,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=None,\n",
      "                                                     splitter='best')),\n",
      "                             ('rfc',\n",
      "                              RandomForestClassifier(boots...\n",
      "                                            beta_2=0.999, early_stopping=False,\n",
      "                                            epsilon=1e-08,\n",
      "                                            hidden_layer_sizes=(100,),\n",
      "                                            learning_rate='constant',\n",
      "                                            learning_rate_init=0.001,\n",
      "                                            max_iter=200, momentum=0.9,\n",
      "                                            n_iter_no_change=10,\n",
      "                                            nesterovs_momentum=True,\n",
      "                                            power_t=0.5, random_state=None,\n",
      "                                            shuffle=True, solver='adam',\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=False, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[1378  200]\n",
      " [ 255 1470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      1578\n",
      "           1       0.88      0.85      0.87      1725\n",
      "\n",
      "    accuracy                           0.86      3303\n",
      "   macro avg       0.86      0.86      0.86      3303\n",
      "weighted avg       0.86      0.86      0.86      3303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "voting = ensemble.VotingClassifier(classifiers)\n",
    "\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', voting)])\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pr = model_selection.cross_val_predict(pipe, features, labels, cv=5)\n",
    "warnings.simplefilter(\"default\")\n",
    "    \n",
    "print(voting)\n",
    "print(metrics.confusion_matrix(labels, pr))\n",
    "print(metrics.classification_report(labels, pr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
