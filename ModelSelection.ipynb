{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets construct the different models that we will use.\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "# read data engineered csv\n",
    "df = pd.read_csv('H-2B_Engineered_Data.csv')\n",
    "labels = df.loc[:,'CASE_STATUS']\n",
    "features = pd.DataFrame(df.drop(labels = ['CASE_STATUS'], axis = 1))\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "#classifiers\n",
    "norm_tree = tree.DecisionTreeClassifier()\n",
    "classifiers.append(('tree', norm_tree))\n",
    "depth_tree = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "classifiers.append(('depth_tree', depth_tree))\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "classifiers.append(('knn', knn))\n",
    "nb = naive_bayes.GaussianNB()\n",
    "classifiers.append(('nb', nb))\n",
    "sv = svm.SVC(gamma = 'auto')\n",
    "classifiers.append(('svm', sv))\n",
    "net = neural_network.MLPClassifier()\n",
    "classifiers.append(('neural_network', net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56    2870\n",
       "72    1152\n",
       "23     769\n",
       "71     705\n",
       "11     203\n",
       "31     122\n",
       "33     103\n",
       "32      91\n",
       "54      73\n",
       "44      68\n",
       "48      66\n",
       "42      64\n",
       "21      57\n",
       "81      49\n",
       "61      48\n",
       "53      42\n",
       "45      14\n",
       "22      12\n",
       "62      12\n",
       "55      11\n",
       "51       3\n",
       "49       2\n",
       "92       2\n",
       "52       2\n",
       "Name: NAICS_CODE, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"NAICS_CODE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    3547\n",
       "35     892\n",
       "47     783\n",
       "39     435\n",
       "51     263\n",
       "53     219\n",
       "45     175\n",
       "43      73\n",
       "49      45\n",
       "41      44\n",
       "33      21\n",
       "27      18\n",
       "11      10\n",
       "31       4\n",
       "25       3\n",
       "17       3\n",
       "29       2\n",
       "19       1\n",
       "15       1\n",
       "13       1\n",
       "Name: SOC_CODE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"SOC_CODE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import neighbors as knn\n",
    "from sklearn import pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Build a preprocessor to scale numeric features and one hot encode categorical features\n",
    "numeric_features = ['NBR_WORKERS_REQUESTED', \n",
    "                    'BASIC_NUMBER_OF_HOURS', \n",
    "                    'BASIC_RATE_OF_PAY', \n",
    "                    'SUPERVISE_HOW_MANY', \n",
    "                    'NUM_OF_MONTHS_TRAINING',\n",
    "                    'EMP_EXP_NUM_MONTHS',\n",
    "                    'WORK_DAY_LENGTH']\n",
    "numeric_transformer = pipeline.Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())])\n",
    "\n",
    "categorical_features = ['SOC_CODE',\n",
    "                        'NAICS_CODE',\n",
    "                       'NATURE_OF_TEMPORARY_NEED',\n",
    "                       'EDUCATION_LEVEL',\n",
    "                       'CITY_MATCH',\n",
    "                       'STATE_MATCH']\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder(sparse = False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[[ 314  475]\n",
      " [ 584 5167]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.40      0.37       789\n",
      "           1       0.92      0.90      0.91      5751\n",
      "\n",
      "    accuracy                           0.84      6540\n",
      "   macro avg       0.63      0.65      0.64      6540\n",
      "weighted avg       0.85      0.84      0.84      6540\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[[ 264  525]\n",
      " [ 271 5480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.33      0.40       789\n",
      "           1       0.91      0.95      0.93      5751\n",
      "\n",
      "    accuracy                           0.88      6540\n",
      "   macro avg       0.70      0.64      0.67      6540\n",
      "weighted avg       0.86      0.88      0.87      6540\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[[ 268  521]\n",
      " [ 235 5516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.34      0.41       789\n",
      "           1       0.91      0.96      0.94      5751\n",
      "\n",
      "    accuracy                           0.88      6540\n",
      "   macro avg       0.72      0.65      0.68      6540\n",
      "weighted avg       0.87      0.88      0.87      6540\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[[ 250  539]\n",
      " [ 474 5277]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.32      0.33       789\n",
      "           1       0.91      0.92      0.91      5751\n",
      "\n",
      "    accuracy                           0.85      6540\n",
      "   macro avg       0.63      0.62      0.62      6540\n",
      "weighted avg       0.84      0.85      0.84      6540\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[[ 126  663]\n",
      " [  31 5720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27       789\n",
      "           1       0.90      0.99      0.94      5751\n",
      "\n",
      "    accuracy                           0.89      6540\n",
      "   macro avg       0.85      0.58      0.60      6540\n",
      "weighted avg       0.88      0.89      0.86      6540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "[[ 293  496]\n",
      " [ 204 5547]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.37      0.46       789\n",
      "           1       0.92      0.96      0.94      5751\n",
      "\n",
      "    accuracy                           0.89      6540\n",
      "   macro avg       0.75      0.67      0.70      6540\n",
      "weighted avg       0.88      0.89      0.88      6540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# The results from the individual classifiers\n",
    "\n",
    "for name, cl in classifiers:\n",
    "    pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', cl)])\n",
    "    pr = model_selection.cross_val_predict(pipe, features, labels, cv = 5)\n",
    "    \n",
    "    print(cl)\n",
    "    print(metrics.confusion_matrix(labels, pr))\n",
    "    print(metrics.classification_report(labels, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/trent/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('tree',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=None,\n",
      "                                                     splitter='best')),\n",
      "                             ('depth_tree',\n",
      "                              DecisionTreeClassifi...\n",
      "                                            beta_2=0.999, early_stopping=False,\n",
      "                                            epsilon=1e-08,\n",
      "                                            hidden_layer_sizes=(100,),\n",
      "                                            learning_rate='constant',\n",
      "                                            learning_rate_init=0.001,\n",
      "                                            max_iter=200, momentum=0.9,\n",
      "                                            n_iter_no_change=10,\n",
      "                                            nesterovs_momentum=True,\n",
      "                                            power_t=0.5, random_state=None,\n",
      "                                            shuffle=True, solver='adam',\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=False, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[ 296  493]\n",
      " [ 201 5550]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.38      0.46       789\n",
      "           1       0.92      0.97      0.94      5751\n",
      "\n",
      "    accuracy                           0.89      6540\n",
      "   macro avg       0.76      0.67      0.70      6540\n",
      "weighted avg       0.88      0.89      0.88      6540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "voting = ensemble.VotingClassifier(classifiers)\n",
    "\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', voting)])\n",
    "pr = model_selection.cross_val_predict(pipe, features, labels, cv = 5)\n",
    "    \n",
    "print(voting)\n",
    "print(metrics.confusion_matrix(labels, pr))\n",
    "print(metrics.classification_report(labels, pr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
