{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets construct the different models that we will use.\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "# read data engineered csv\n",
    "# df = pd.read_csv('H-2B_Engineered_Data.csv')\n",
    "df = pd.read_csv('H-2B_Engineered_Data_Both.csv')\n",
    "# df = pd.read_csv('H-2B_Engineered_Data_Downsampling_Only.csv')\n",
    "labels = df.loc[:,'CASE_STATUS']\n",
    "features = pd.DataFrame(df.drop(labels = ['CASE_STATUS'], axis = 1))\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "#classifiers\n",
    "norm_tree = tree.DecisionTreeClassifier()\n",
    "classifiers.append(('tree', norm_tree))\n",
    "depth_tree = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "classifiers.append(('depth_tree', depth_tree))\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "classifiers.append(('knn', knn))\n",
    "nb = naive_bayes.GaussianNB()\n",
    "classifiers.append(('nb', nb))\n",
    "sv = svm.SVC(gamma = 'auto')\n",
    "classifiers.append(('svm', sv))\n",
    "net = neural_network.MLPClassifier()\n",
    "classifiers.append(('neural_network', net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56    1151\n",
       "23     680\n",
       "72     511\n",
       "71     272\n",
       "11     103\n",
       "32      73\n",
       "33      63\n",
       "48      61\n",
       "81      58\n",
       "54      53\n",
       "21      51\n",
       "31      47\n",
       "44      42\n",
       "42      40\n",
       "53      21\n",
       "62      20\n",
       "61      19\n",
       "45      14\n",
       "22       9\n",
       "51       7\n",
       "55       4\n",
       "52       2\n",
       "49       1\n",
       "92       1\n",
       "Name: NAICS_CODE, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"NAICS_CODE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    1394\n",
       "47     710\n",
       "35     407\n",
       "39     202\n",
       "51     178\n",
       "53     155\n",
       "45      84\n",
       "49      40\n",
       "43      35\n",
       "41      30\n",
       "27      18\n",
       "11      15\n",
       "33      11\n",
       "25       7\n",
       "13       5\n",
       "31       4\n",
       "29       2\n",
       "19       2\n",
       "17       2\n",
       "15       2\n",
       "Name: SOC_CODE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"SOC_CODE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import neighbors as knn\n",
    "from sklearn import pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Build a preprocessor to scale numeric features and one hot encode categorical features\n",
    "numeric_features = ['NBR_WORKERS_REQUESTED', \n",
    "                    'BASIC_NUMBER_OF_HOURS', \n",
    "                    'BASIC_RATE_OF_PAY', \n",
    "                    'SUPERVISE_HOW_MANY', \n",
    "                    'NUM_OF_MONTHS_TRAINING',\n",
    "                    'EMP_EXP_NUM_MONTHS',\n",
    "                    'WORK_DAY_LENGTH']\n",
    "numeric_transformer = pipeline.Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())])\n",
    "\n",
    "categorical_features = ['SOC_CODE',\n",
    "                        'NAICS_CODE',\n",
    "                       'NATURE_OF_TEMPORARY_NEED',\n",
    "                       'EDUCATION_LEVEL',\n",
    "                       'CITY_MATCH',\n",
    "                       'STATE_MATCH']\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder(sparse = False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[[1452  126]\n",
      " [ 290 1435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1578\n",
      "           1       0.92      0.83      0.87      1725\n",
      "\n",
      "    accuracy                           0.87      3303\n",
      "   macro avg       0.88      0.88      0.87      3303\n",
      "weighted avg       0.88      0.87      0.87      3303\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "[[1333  245]\n",
      " [ 265 1460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1578\n",
      "           1       0.86      0.85      0.85      1725\n",
      "\n",
      "    accuracy                           0.85      3303\n",
      "   macro avg       0.85      0.85      0.85      3303\n",
      "weighted avg       0.85      0.85      0.85      3303\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[[1318  260]\n",
      " [ 345 1380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1578\n",
      "           1       0.84      0.80      0.82      1725\n",
      "\n",
      "    accuracy                           0.82      3303\n",
      "   macro avg       0.82      0.82      0.82      3303\n",
      "weighted avg       0.82      0.82      0.82      3303\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[[ 599  979]\n",
      " [ 238 1487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.38      0.50      1578\n",
      "           1       0.60      0.86      0.71      1725\n",
      "\n",
      "    accuracy                           0.63      3303\n",
      "   macro avg       0.66      0.62      0.60      3303\n",
      "weighted avg       0.66      0.63      0.61      3303\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "[[1167  411]\n",
      " [ 283 1442]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1578\n",
      "           1       0.78      0.84      0.81      1725\n",
      "\n",
      "    accuracy                           0.79      3303\n",
      "   macro avg       0.79      0.79      0.79      3303\n",
      "weighted avg       0.79      0.79      0.79      3303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "[[1287  291]\n",
      " [ 231 1494]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1578\n",
      "           1       0.84      0.87      0.85      1725\n",
      "\n",
      "    accuracy                           0.84      3303\n",
      "   macro avg       0.84      0.84      0.84      3303\n",
      "weighted avg       0.84      0.84      0.84      3303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# The results from the individual classifiers\n",
    "\n",
    "for name, cl in classifiers:\n",
    "    pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', cl)])\n",
    "    pr = model_selection.cross_val_predict(pipe, features, labels, cv = 5)\n",
    "    \n",
    "    print(cl)\n",
    "    print(metrics.confusion_matrix(labels, pr))\n",
    "    print(metrics.classification_report(labels, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('tree',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=None,\n",
      "                                                     splitter='best')),\n",
      "                             ('depth_tree',\n",
      "                              DecisionTreeClassifi...\n",
      "                                            beta_2=0.999, early_stopping=False,\n",
      "                                            epsilon=1e-08,\n",
      "                                            hidden_layer_sizes=(100,),\n",
      "                                            learning_rate='constant',\n",
      "                                            learning_rate_init=0.001,\n",
      "                                            max_iter=200, momentum=0.9,\n",
      "                                            n_iter_no_change=10,\n",
      "                                            nesterovs_momentum=True,\n",
      "                                            power_t=0.5, random_state=None,\n",
      "                                            shuffle=True, solver='adam',\n",
      "                                            tol=0.0001, validation_fraction=0.1,\n",
      "                                            verbose=False, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[1363  215]\n",
      " [ 266 1459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1578\n",
      "           1       0.87      0.85      0.86      1725\n",
      "\n",
      "    accuracy                           0.85      3303\n",
      "   macro avg       0.85      0.85      0.85      3303\n",
      "weighted avg       0.85      0.85      0.85      3303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "voting = ensemble.VotingClassifier(classifiers)\n",
    "\n",
    "pipe = pipeline.Pipeline(steps = [('preprocess', preprocessor), ('dim', decomposition.PCA()), ('classifier', voting)])\n",
    "pr = model_selection.cross_val_predict(pipe, features, labels, cv = 5)\n",
    "    \n",
    "print(voting)\n",
    "print(metrics.confusion_matrix(labels, pr))\n",
    "print(metrics.classification_report(labels, pr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
